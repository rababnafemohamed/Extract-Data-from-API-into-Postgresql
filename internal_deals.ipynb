{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d95b7e2-fa21-444d-ac45-e98c60f61e62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install psycopg2\n",
    "%pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2d93d84-9ec7-44a2-a372-7f034dc525ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    " %restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f0430f1-2962-4801-87f3-02b713bb4a24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Let's import needed libraries and classes\n",
    "import requests\n",
    "import json\n",
    "from cryptography.fernet import Fernet\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import length, col\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0925061-9992-4853-9b21-87dda372b728",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Let's read the config file \n",
    "with open('config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73e42bf2-4dc3-4682-91a5-b6f3d476f82f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import the function from the Python file\n",
    "from process_urls import process_urls\n",
    "\n",
    "# Get the list of URLs from the config and modify the URL format\n",
    "urls = [url.replace(\"/tracker/mileage_logs\", \"/internal/deals\") for url in config['track_milage_logs_urls']]\n",
    "# Process the URLs to get a list of DataFrames\n",
    "dataframes = process_urls(urls)\n",
    "\n",
    "def merge_dataframes(dataframes):\n",
    "    if dataframes:\n",
    "        # Concatenate all DataFrames in the list into a single DataFrame\n",
    "        final_dataframe = pd.concat(dataframes)\n",
    "        return final_dataframe\n",
    "    else:\n",
    "        print(\"No DataFrames to concatenate\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Merge the list of DataFrames into a single DataFrame\n",
    "final_dataframe = merge_dataframes(dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09eabd01-ed34-4a77-90c2-3ff17e80cc9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To take into account in the final analysis, I was not able to load the data for the last month of 2024 due to a server error. I have tried to load partial data for the month but still got the same error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ecb3479-50f6-4797-b064-a95dc07fbbae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "final_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45f6af17-f923-4fc8-9307-7c2237275c24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We will remove duplicate values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04687512-a6aa-4219-b5a2-cdd1bad72de0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "No_duplicate_data = final_dataframe.drop_duplicates()\n",
    "No_duplicate_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33c3e37a-1bd8-49fb-84d9-0ea6052fd3e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "No_duplicate_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0cdae9a9-29a2-48f4-8d87-ad9a7482694e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "No_duplicate_data.rename(columns={'_id':'id', '_stage_n':'stage_n', '_stage':'stage', '_create_date':'create_date', '_is_deleted':'is_deleted'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a14a98e-bff2-4860-a6a9-748657bd9fb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# as missing values in only once record we will remove it \n",
    "No_duplicate_data = No_duplicate_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5316323e-bafa-4123-bd09-d673268d7df4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Read configuration from the JSON file\n",
    "with open('config_db.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "dbname = config[\"dbname\"]\n",
    "user = config[\"user\"]\n",
    "password = config[\"password\"]\n",
    "host = config[\"host\"]\n",
    "port = config[\"port\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6633cff6-40ea-409b-b610-f5f0ea23da2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(No_duplicate_data)\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = create_engine(f'postgresql+psycopg2://{user}:{password}@{host}:{port}/{dbname}')\n",
    "\n",
    "# Upload the dataframe to the PostgreSQL database as a table\n",
    "table_name = 'Internal_Deals'\n",
    "df.to_sql(table_name, engine, index=False, if_exists='replace')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "internal_deals",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
